\section{Introduction}

The Lattice Expression Language (just a fancy name for some C++ classes !)
allows manipulation of mathematical expressions involving {\tt Lattices}
directly from C++.  The {\tt Lattices} involved in the expressions are
iterated through tile by tile, and the expression evaluated for each
pixel in the tiles.  Thus there are no large temporary {\tt Lattices}, and the
iteration is efficient.   

LEL offers many of the standard numerical and logical operators and
functions (that can be applied to scalars and {\tt Arrays}), as well as
some additional astronomically oriented ones.  It can handle {\tt
Float}, {\tt Double}, {\tt Complex} and {\tt DComplex} {\tt Lattices},
including expressions involving mixtures of these types of {\tt
Lattices}.  Conversion of data types is automatic, although the user can
also embed explicit conversions. 

The user can build expressions from subexpressions, finally evaluating
the final expression.  

Throughout this document we will refer to objects of class
{\tt Lattice}.  In reality, this is an abstract class and
the real objects would be derived from it.

\section {Class Structures}

The expression is parsed, by the compiler, into a tree, and the nodes of
the tree are built with the LEL classes.  The tree is also evaluated
with the LEL classes. 

LEL is implemented with a Letter/Envelope scheme.  The relational
structure between the classes is straightforward.  The Envelope class is
{\tt LatticeExpr}.  {\tt LatticeExpr} invokes {\tt LatticeExprNode},
which provides a bridge from {\tt LatticeExpr} to the letter classes
{\tt LELBinary}, {\tt LELBinaryCmp}, {\tt LELBinaryBool}, {\tt
LELConvert}, {\tt LELFunction1D}, {\tt LELFunctionND}, {\tt
LELFunctionReal1D}, {\tt LELFunctionFloat}, {\tt LELFunctionDouble},
{\tt LELFunctionComplex}, {\tt LELFunctionDComplex}, {\tt
LELFunctionBool}, {\tt LELLattice}, {\tt LELUnaryConst}, {\tt LELUnary},
and {\tt LELUnaryBool}.  The letter classes all inherit from {\tt
LELInterface} which defines their common interface.  There is one more
class, {\tt LELAttribute}, which is a helper class containing some
attribute information about the expression. 
 
The purpose of the bridge class, {\tt LatticeExprNode} is to handle type
conversions.  If all the data were of the same type (e.g.  {\tt Float})
we would not need the bridge class and {\tt LatticeExpr} would directly
invoke the letter classes. 

The user is exposed to the classes {\tt LatticeExpr} and {\tt LatticeExprNode}. 
Exposure to {\tt LatticeExpr} is largely implicit (see later).  Use of
{\tt LatticeExprNode} may be explicit if subexpression manipulation is
desired. 

The classes are

\begin{center}
\begin{tabular}{|l|l|l|l|l}
\hline
\multicolumn{5}{|c|}{{\bf LEL Classes}} \\
\hline
Class & Source files & templation & inheritance & use\\
\hline
LatticeExpr & LatticeExpr.\{h,cc\} &   $<T>$ & Lattice$<T>$ & Envelope \\
LatticeExprNode & LatticeExprNode.\{h,cc\} & none & none & bridge \\
LELAttribute  &  LELAttribute.\{h,cc\}  & none & none & helper \\
LELInterface & LELInterface.\{h,cc\}  & $<T>$ & none & Base class \\
LELBinaryEnums & LELBinaryEnums.h & none & none & Enum \\
LELBinary & LELBinary.\{h,cc\} & $<T>$ & LELInterface$<T>$ & letter class \\
LELBinaryCmp & LELBinary.\{h,cc\} &  $<T>$ & LELInterface$<$Bool$>$ & letter class \\
LELBinaryBool & LELBinary\{.h,2.cc\} & none & LELInterface$<$Bool$>$ & letter class \\
LELConvert & LELConvert.\{h,cc\} & $<T,F>$ & LELInterface$<T>$ & letter class \\
LELFunctionEnums & LELFunctionEnums.h & none & none & enum \\
LELFunction1D & LELFunction.\{h,cc\}& $<T>$ & LELInterface$<T>$ & letter class \\
LELFunctionND & LELFunction.\{h,cc\}& $<T>$ & LELInterface$<T>$ & letter class \\
LELFunctionReal1D & LELFunction.\{h,cc\}& $<T>$ & LELInterface$<T>$ & letter class \\
LELFunctionFloat & LELFunction\{.h,2.cc\} & none & LELInterface$<$Float$>$ & letter class \\
LELFunctionDouble & LELFunction\{.h,2.cc\} & none & LELInterface$<$Double$>$ & letter class \\
LELFunctionComplex & LELFunction\{.h,2.cc\} & none & LELInterface$<$Complex$>$ & letter class \\
LELFunctionDComplex & LELFunction\{.h,2.cc\} & none & LELInterface$<$DComplex$>$ & letter class \\
LELFunctionBool  & LELFunction\{.h,2.cc\} & none & LELInterface$<$Bool$>$ & letter class \\
LELLattice  & LELLattice.\{h,cc\} &  $<T>$ & LELInterface$<T>$ & letter class \\
LELUnaryEnums & LELUnaryEnums.h & none & none & enum \\
LELUnaryConst & LELUnary.\{h,cc\} & $<T>$ & LELInterface$<T>$ & letter class \\
LELUnary   & LELUnary.\{h,cc\} & $<T>$ & LELInterface$<T>$ & letter class \\
LELUnaryBool  & LELUnary\{.h,2.cc\} & none & LELInterface$<$Bool$>$ & letter class \\
\hline
\end{tabular}
\end{center}


\section {How It Works}

Let us look at an example expression and examined how the system works.

For example,

\begin{verbatim}
   Lattice<Float> a;
   Lattice<Float> b;
   Lattice<Double> c;
   a.copyData(b+c);
\end{verbatim}

Thus, we evaluate the sum of the {\tt Lattices} {\tt b} and {\tt c} and fill
the {\tt Lattice} {\tt a} with the result.  Note that the result of {\tt b+c} is a
{\tt Double} {\tt Lattice} which will be assigned to a {\tt Float} {\tt Lattice}. 

There are two distinct steps in this; the first is the creation of the
expression tree.  The second is the evaluation of the tree after its
creation.  Both occur at run time; the creation first, and then, via the
{\tt copyData} call, the evaluation. 

The tree is a structure which can be thought of as representing
the hierarchy of operations.  For our example above, it looks like

\begin{verbatim}
     +
   b   c
\end{verbatim}

Really, {\tt b} and {\tt c} are not operations, the actual software
operation is something that gets the values of the {\tt Lattice} into core
from the {\tt Lattice}.  The tree is more accurately written as

\begin{verbatim}
                     +
  getLatticeValues       getLatticeValues
     b                          c
\end{verbatim}

but we will use the short-hand tree expression style.

A more complex expression like  {\tt (a+sin(b)+2) / 10}
would be

\begin{verbatim}
               / 
         +          10.0
    +        a
sin    2.0
b
\end{verbatim}

The tree is evaluated bottom up.  Conceptually, the {\tt sin} of the {\tt Lattice}
{\tt b} is evaluated and {\tt 2.0} added to the resultant {\tt Lattice}.  Then that
is added to the {\tt Lattice} {\tt a}, and that resultant {\tt Lattice} is divided
by {\tt 10.0}.




\subsection {Tree Creation}

Let us consider the creation of the expression tree first.  The {\tt
Lattice::copyData} member function expects as its argument a {\tt
Lattice}.  Thus, the expression in the argument has to find a way to be
converted to a {\tt Lattice}.  It is the LatticeExpr class that knows
how to evaluate expressions involving {\tt Lattices}, and LatticeExpr
inherits from {\tt Lattice}.  So any {\tt LatticeExpr} object is a valid
argument for the copyData call.  We need to show that {\tt b+c} is a
{\tt Lattice}; in this case a {\tt LatticeExpr} object, derived from
{\tt Lattice}. 

Internally, {\tt LatticeExpr} contains a {\tt LatticeExprNode} object,
so let us consider class {\tt LatticeExprNode} first.  {\tt
LatticeExprNode} exists to handle type conversions for mixed type
expressions.  It is a non-templated class and is not derived from any
other class.  It contains, as private data members, a variety of
pointers to the class {\tt LELInterface}.  {\tt LELInterface} is an
abstract base class, from which are derived concrete classes.  These
derived classes are constructed in the tree, and when the expression is
evaluated, they enable one to evaluate expressions such as binary
expressions, or functions, or get chunks of a {\tt Lattice} etc.  These
derived classes are (mostly) templated, and the {\tt LatticeExprNode}
class contains one {\tt LELInterface} pointer object for each
conceivable type ({\tt Float}, {\tt Double}, {\tt Complex}, and {\tt
DComplex}).  The appropriate type for the {\tt LELInterface} pointer and
the templated derived {\tt LELInterface} object it is pointing to is the
type of the data that it is manipulating.  For example, if a {\tt
LELLattice} object is constructed from a {\tt Lattice<Float>} then the
appropriate type is {\tt Float}. 

Now, expressions like {\tt b} and {\tt c} can be converted to {\tt
LatticeExprNode} objects via constructors such as

\begin{verbatim}
   LatticeExprNode(const Lattice<Float>& lattice);
   LatticeExprNode(const Lattice<Double>& lattice);
\end{verbatim}

Recall that the {\tt LatticeExprNode} object contains private data
members ({\tt LELInterface} pointers) of many different types.  Only the
data member of the relevant type will be assigned.  For example, the
Float constructor looks like

\begin{verbatim}
   LatticeExprNode::LatticeExprNode (const Lattice<Float>& lattice)
   : donePrepare_p (False),
     dtype_p       (TpFloat),
     pExprFloat_p  (new LELLattice<Float> (lattice)) 
   {
      pAttr_p = &pExprFloat_p->getAttribute();
   }
\end{verbatim}

The constructor notes that no optimizations (see later) have been
performed, and also notes what type of data it is being asked to handle. 
Now look at the {\tt new} statement.  A pointer ({\tt pExprFloat}$_{\tt p}$
of type {\tt LELInterface<Float>}) to an object of class
{\tt LELLattice} is created ({\tt LELLattice} is a class derived from
{\tt LELInterface}, the abstract base class). 

Thus, from the expressions {\tt b} or {\tt c}, we can create {\tt
LatticeExprNode} objects from the {\tt Lattice} objects associated with
{\tt b} and {\tt c}.  We must now look at the full expression, {\tt
b+c}.  Remember that {\tt Lattice} {\tt b} is of type {\tt Float} and
{\tt Lattice} {\tt c} is of type {\tt Double}, and the output {\tt
Lattice} {\tt a} is of type {\tt Float} (and therefore copyData is
expecting a {\tt Lattice<Float>} for its argument). 

{\tt LatticeExprNode} has an operator $+$ function declared as

\begin{verbatim}
   friend LatticeExprNode operator+ (const LatticeExprNode& left,  
                                     const LatticeExprNode& right);
\end{verbatim}


The friend keyword makes it a globally accessible operator.  Now, you
can see that it takes two other {\tt LatticeExprNode} objects, in our case,
those that we made from {\tt b} and {\tt c}.

The $+$ operator returns another {\tt LatticeExprNode} object; it is defined as

\begin{verbatim}
   LatticeExprNode operator+ (const LatticeExprNode& left,
                              const LatticeExprNode& right)
   {
      return LatticeExprNode::newNumBinary (LELBinaryEnums::ADD, left, right);
   }
\end{verbatim}

where the static function {\tt LatticeExprNode::newNumBinary} has returned the
desired {\tt LatticeExprNode} object (which embodies the two subexpression, {\tt b} and
{\tt c}).

Now, recall that what we really want in the copyData call is an object
of type {\tt LatticeExpr} (which is a {\tt Lattice}).  Currently we have a
{\tt LatticeExprNode} object.  So there has to be an automatic conversion 
from the non-templated {\tt LatticeExprNode} object to the templated {\tt LatticeExpr}
object.   This is done with one of the operators in {\tt LatticeExprNode}
from the list

\begin{verbatim}
   operator LatticeExpr<Float>();
   operator LatticeExpr<Double>();
   operator LatticeExpr<Complex>();
   operator LatticeExpr<DComplex>();
   operator LatticeExpr<Bool>();
\end{verbatim}

For reasons that we don't understand, this could not be made to
work yet with a constructor of the type

\begin{verbatim}
   LatticeExpr (const LatticeExprNode& expr)
\end{verbatim}


These operators are are in reality casting operators.    For example,
if you had

\begin{verbatim}
   Double x; 
   Int i;  
   x = (Double)i;
\end{verbatim}

the {\tt i} would be cast to a {\tt Double}.  Similarly, 

\begin{verbatim}
   LatticeExprNode node; 
   LatticeExpr<Float> expr; 
   expr = (LatticeExpr<Float>)node;
\end{verbatim}

converts the node to the {\tt expr}.

Since they are in class {\tt LatticeExprNode}, they expect to operate on a
{\tt LatticeExprNode} object.  The name of the operator is the same as the
return type: {\tt LatticeExpr<T>} This is in general a dangerous practice, as
one gets automatic conversions that weren't wanted sometimes.  But we
seem to have no choice for now. 

Now, for our example, the type that {\tt Lattice::copyData} is expecting is
a {\tt Float}, because that is the type of the {\tt Lattice} {\tt a}.  Therefore,
the casting operator that will be invoked is

\begin{verbatim}
   LatticeExprNode::operator LatticeExpr<Float>()
  {
      return LatticeExpr<Float> (LatticeExprNode(makeFloat()), 0);
   }
\end{verbatim}

So a {\tt LatticeExpr} constructor of the form

\begin{verbatim}
   LatticeExpr (const LatticeExprNode& expr, uInt iDummy)
\end{verbatim}

is explicitly invoked by this casting operator.  First however, the {\tt
makeFloat} function is invoked explicitly to convert the data in the
{\tt LatticeExprNode} object to the correct internal type, which is {\tt
Float} for our example.  Actually, the return type from {\tt makeFloat} is a
{\tt CountedPtr<LELInterface<Float>>}.  Therefore, to convert that to a {\tt
LatticeExprNode}, the constructor

\begin{verbatim}
   LatticeExprNode(LELInterface<Float>* expr);
\end{verbatim}

is automatically invoked.  This is given to the {\tt LatticeExpr} constructor
and finally returned. 

Now returning to the {\tt newNumBinary} static function above, there is
another subtlety being handled.  Here is where we handle some additional
type conversion.  We know that {\tt Lattice} {\tt a} wants a {\tt Float}
{\tt Lattice} in the {\tt Lattice::copyData} function.  We saw above that the
{\tt newNumBinary} static function produced a {\tt LatticeExprNode} which was
automatically converted to a {\tt LatticeExpr} object of type Float. 
The thing we didn't see yet was how the handling of the mixed type
expression {\tt b+c} was dealt with by {\tt newNumBinary}. That is, we don't know
yet what the type of {\tt b+c} was, although we know that {\tt makeFloat} was able
to handle it, whatever it was.  So let us look inside {\tt newNumBinary}.

This function is implemented as

\begin{verbatim}
   LatticeExprNode LatticeExprNode::newNumBinary (LELBinaryEnums::Operation oper,
                                                  const LatticeExprNode& left,
                                                  const LatticeExprNode& right)   
   {   
      DataType dtype = resultDataType (left.dataType(), right.dataType());
      switch (dtype) {
      case TpFloat:
         return new LELBinary<Float> (oper, left.makeFloat(),
                                      right.makeFloat());
      case TpDouble:
         return new LELBinary<Double> (oper, left.makeDouble(),
                                       right.makeDouble());
      case TpComplex:
         return new LELBinary<Complex> (oper, left.makeComplex(),
                                        right.makeComplex());
      case TpDComplex:
         return new LELBinary<DComplex> (oper, left.makeDComplex(),
                                         right.makeDComplex());
      default:
         throw (AipsError
               ("LatticeExpr: Bool argument used in numerical binary operation"));
      }
      return LatticeExprNode();
   }
\end{verbatim}


This function returns an expression of one type, as the two expressions
that go into it may have different types.  Indeed, in our case, the left
expression is a {\tt Float} and the right a {\tt Double}.  The function
{\tt LatticeExprNode::resultDataType} says that mixing these two types should
result in a {\tt Double} so as not to lose precision.  Therefore, the left
and right expressions are converted to a {\tt Double} expression and the
{\tt LELBinary} object that is created is a {\tt Double} (see also the
section on type conversions).

In addition, it can be seen that the return statements are returning
pointers to objects of type {\tt LELBinary}, which is derived from {\tt
LELInterface}.  Yet, the function {\tt newNumBinary} actually returns an
object of type {\tt LatticeExprNode}.  So what is happening is an
implicit conversion via a constructor.  It's one of the private
constructors

\begin{verbatim}
   LatticeExprNode(LELInterface<Float>* expr);
   LatticeExprNode(LELInterface<Double>* expr);
   LatticeExprNode(LELInterface<Complex>* expr);
   LatticeExprNode(LELInterface<DComplex>* expr);
   LatticeExprNode(LELInterface<Bool>* expr);
\end{verbatim}

that is doing the work.



\subsection {Evaluation}

How does {\tt copyData} manage to extract the result of the expression
evaluation ? The {\tt copyData} function ultimately calls the {\tt
Lattice} function {\tt getSlice} (via an iterator) to fish out the data
from its {\tt Lattice} argument.  {\tt getSlice} is therefore
implemented in {\tt LatticeExpr} (as it inherits from {\tt Lattice}
where {\tt getSlice} is declared).  We have seen that {\tt LatticeExpr}
has one private data member, and it is of type {\tt LatticeExprNode}. 
The implementation of {\tt LatticeExpr::getSlice} is to call the {\tt
eval} function of its {\tt LatticeExprNode} private data member (recall
that {\tt LatticeExprNode} has a variety of pointers like {\tt
CountedPtr<LELInterface<Float>>} for each data type).  {\tt
LatticeExprNode} has many self-similar {\tt eval} functions, one for
each type ({\tt Float, Double} etc).  Although the {\tt LatticeExprNode}
object does know for what type it was constructed, it actually chooses
the correct version of the {\tt eval} function by the argument
signature.  This works because a buffer is included in the {\tt eval}
interface (this is where the result of the expression is put), and the
buffer is of the appropriate type. 

So invoking {\tt eval} of {\tt LatticeExprNode} invokes {\tt eval} of
the object (which has been derived from {\tt LELInterface}) and is
pointed to by the appropriately typed {\tt
CountedPtr<LELInterface<T>>}.  In our example involving adding two
{\tt Lattices} together, those derived classes would be {\tt LELLattice}
(to read the data from the {\tt Lattice}) and {\tt LELBinary} (to add
the data).  For {\tt LELLattice}, its {\tt eval} function actually then
uses the getSlice function on the actual {\tt Lattice} from which it was
constructed ({\tt b} or {\tt c}) to fish out the data.  The {\tt
LELBinary} {\tt eval} function will add the numbers together. 

Finally, since {\tt copyData} is actually iterating through the {\tt LatticeExpr}
({\tt Lattice}) object in optimally sized chunks.  The {\tt Lattice} expression is
evaluated chunk by chunk (usually tile by tile).  This means that there
are no large temporary {\tt Lattices} stored. 

\begin{verbatim}
   virtual void eval (Array<T>& result,
                      const PixelRegion& region) const = 0;
\end{verbatim}

The derived classes make the actual implementation.  The result of the
evaluation of the expression is put in the {\tt result} array.  If the
result of the expression evaluation is known to be a scalar (figured out
at tree construction time) then the {\tt getScalar} function is used to get
the value instead. 
 

\begin{verbatim}
   virtual T getScalar() const = 0;
\end{verbatim}


Let's look at {\tt eval} implementations for {\tt LELBinary} and
{\tt LELLattice}.  First, the piece for {\tt LELBinary} relevant to
the $+$ operator.

\begin{verbatim}
   template <class T>
   void LELBinary<T>::eval(Array<T>& result,
                           const PixelRegion& region) const
   {
      switch(op_p) {
      case LELBinaryEnums::ADD :
          if (pLeftExpr_p->isScalar()) {
             pRightExpr_p->eval(result, region);
             result += pLeftExpr_p->getScalar();
          } else if (pRightExpr_p->isScalar()) {
             pLeftExpr_p->eval(result, region);
             result += pRightExpr_p->getScalar();
          } else {
             Array<T> temp(result.shape());
             pLeftExpr_p->eval(result, region);
             pRightExpr_p->eval(temp, region);
             result += temp;
          }
          break;
\end{verbatim}

Three cases are handled here: (array,array), (scalar,array) and
(array,scalar).  The case of (scalar,scalar) is handled similarly in
{\tt LELBinary::getScalar}.

The important thing to see here is that the process is recursive.  Each
of the left and right expressions are evaluated first, before the $+$
operation is done.  So for example, since our example is the
(array,array) case, we have

\begin{verbatim}
          Array<T> temp(result.shape());
          pLeftExpr_p->eval(result, region);
          pRightExpr_p->eval(temp, region);
          result += temp;
\end{verbatim}


Both the left and right expressions are {\tt LELLattice} objects.  Evaluating
them results in filling the {\tt result} array with the values from the
{\tt Lattice} in the {\tt region}.  Then the two arrays ({\tt result} and {\tt temp}) are
added to make the binary operation result.  The {\tt LELLattice} eval function
looks like


\begin{verbatim}
   template <class T>
   void LELLattice<T>::eval(Array<T>& result,
                            const PixelRegion& region) const
   {
   // The rwRef function will make a copy when needed (i.e. when ptr
   // contains a reference to the original data).
    
      COWPtr<Array<T> > ptr;
      pLattice_p->getSlice(ptr, region.box(), False);
      result.reference(ptr.rwRef());
   }
\end{verbatim}
 
the {\tt Lattice} function {\tt getSlice} is used to recover the pixels
into the array {\tt result}.  Note we use a {\tt COWPtr} so that for say
an {\tt ArrayLattice}, the array references the data only saving a copy,
unless it is actually written to.  There is no {\tt
LELLattice::getScalar} function as it doesn't make any sense.  If you
try to call it, you will throw an exception. 



\section {Data Type Conversions}

There are two types of conversion going on in these classes, and one can
get rather confused between them if not careful.  

\begin{itemize}
\item There are conversions imposed by the {\tt C++} compiler. These convert
     from {\tt Lattice<T>} to {\tt LatticeExprNode}
     and from {\tt LatticeExprNode} to {\tt LatticeExpr<T>}
\item There are conversions done by the expression classes to convert from one
   data type to another (e.g. {\tt Float} to {\tt Double}).
   They are run-time conversions generated by the {\tt makeXXX} functions.
\end{itemize}
  
The first type of conversion (e.g.  {\tt LatticeExprNode} to {\tt
LatticeExpr<T>}) is handled by the casting operator discussed
previously.  In addition, inside that casting operation are calls to
functions like {\tt LatticeExprNode::makeFloat} which embed an object of
class {\tt LELConvert} into the tree and then at evaluation time {\tt
LELConvert::eval} actually converts the data (i.e.  the values of the
pixels in the {\tt eval} interface buffer array) between types so that
the {\tt LatticeExpr<T>} {\tt T} type is self-consistent with the
type of the {\tt LELInterface} {\tt CountedPtr} inside {\tt
LatticeExprNode} (and hence the right-type eval functions get picked up
in {\tt LatticeExprNode}). 

Let us look a little harder at the conversion functions like {\tt
LatticeExprNode::makeDouble} (and similar expressions) that does the
type conversion for the actual data arrays in the {\tt
LELInterface::eval} interface.  Here is the implementation


\begin{verbatim}
   CountedPtr<LELInterface<Double> > LatticeExprNode::makeDouble() const
   {
       switch (dataType()) {
       case TpFloat:
           return new LELConvert<Double,Float> (pExprFloat_p);
       case TpDouble:
           return pExprDouble_p;
       default:
           throw (AipsError ("LatticeExpr: conversion to Double not possible"));
       }
       return 0;
   }
\end{verbatim}

So what happens is that if a type conversion is required on the {\tt
LatticeExprNode} to which {\tt makeDouble} is being applied, then the
returned {\tt CountedPtr<LELInterface<Double>>} is assigned to a
{\tt LELConvert} object (which inherits from {\tt LELInterface}). 
Otherwise, it just returns the current {\tt
CountedPtr<LELInterface<Double>>} object already active inside the
{\tt LatticeExprNode} ({\tt pExprDouble}$_{\tt p}$).  The {\tt
LELConvert} object is now embedded in the tree.  Note that the actual
conversion will happen at evaluation time, not at tree construction
time, when the {\tt eval} function of {\tt LELConvert} gets called. 
{\tt LELConvert::eval} will actually convert the data in the interface
buffer between types (just by copying). 

Let us look at the actual tree here.  Imagine  we have 

\begin{verbatim}
   Lattice<Float> a;
   Lattice<Double> b;
   LatticeExprNode expr = a+b;
\end{verbatim}

The tree, with all like types, would be

\begin{verbatim}
   +
a     b
\end{verbatim}

Now however, because {\tt a}  and {\tt b} are different types,
we embed a conversion into the tree.  In this case,
the {\tt Float} is converted to a {\tt Double}.

\begin{verbatim}
     +
conv    b
  a
\end{verbatim}   

Now let us assign this result of {\tt a+b} to an output {\tt Lattice}

\begin{verbatim}
   Lattice<Float> c;
   c.copyData(expr);
\end{verbatim}

The type of {\tt a+b} is {\tt Double}, and we need to convert
it to {\tt Float}, the type of {\tt c}.  Thus the tree looks like

\begin{verbatim}
    conv
     +
conv    b
  a
\end{verbatim}


In summary, type conversions of the actual data are handled by embedding
{\tt LELConvert} objects in the tree where necessary.  The embedding is done
by the {\tt LatticeExprNode::makeXXX} functions. 



\section {Scalar Results}


So far, we have assumed that the result of all expressions is of the
same shape.  For example, adding two {\tt Lattices} together where the
{\tt Lattices} have the same shape.  However, we need to also handle
expressions where the resultant of the operation on a {\tt Lattice} is a
scalar.  For example, {\tt min(a)} where the minimum value of the {\tt
Lattice} {\tt a} is returned, must also be handled. 

This is done in two places.  Firstly, when any of the derived {\tt LEL*}
classes are constructed, it is known whether the result of the operation
for which that class exists is a scalar or not.  For example, the class
{\tt LELUnaryConst}, which exists to handle an expression like {\tt 2.0}
knows that its result, after evaluation, is a scalar.  Similarly, class
{\tt LELFunction1D}, when it is handling functions {\tt min}, {\tt max},
{\tt mean} and {\tt sum} (which take one argument) knows that it returns
a scalar.  Otherwise, and for all other classes, it is seen whether the
result of evaluating the tree below is a scalar or not.  If the former,
then the result is also a scalar.  Storage of the knowledge about
whether the result is a scalar or not is handled by the attribute class,
{\tt LELAttribute}.

Secondly, the knowledge that the result of the evaluation of the tree
below the current location is scalar or not is used to optimize the
computation (we could just replicate scalars into arrays of course). 

For example, consider the expression {\tt b+min(c)} where {\tt b} and {\tt c} are
{\tt Lattices}.  The result of {\tt min(c)} is a scalar (we will discuss the
optimization of only evaluating this once later).  Evaluating
{\tt b+min(c)} means that scalar is added to each element of {\tt b} so the
final result is not a scalar. 

The tree looks like

\begin{verbatim}
      +
   b    min
         c
\end{verbatim}

The code handling the binary operator $+$ needs to know whether the
result of the left and right expressions are scalars or not.  For
example, if they were both scalars, it would just add those scalars
together and pass them on up the tree (noting at tree construction time
that its result was scalar).  This operation is handled in the {\tt LELBinary}
class, and the relevant code for the $+$ operation is

\begin{verbatim}
   template <class T>
   void LELBinary<T>::eval(Array<T>& result,
                           const PixelRegion& region) const
  {
      switch(op_p) {
      case LELBinaryEnums::ADD :
          if (pLeftExpr_p->isScalar()) {
             pRightExpr_p->eval(result, region);
             result += pLeftExpr_p->getScalar();
          } else if (pRightExpr_p->isScalar()) {
             pLeftExpr_p->eval(result, region);
             result += pRightExpr_p->getScalar();
          } else {
             Array<T> temp(result.shape());
             pLeftExpr_p->eval(result, region);
             pRightExpr_p->eval(temp, region);
             result += temp;
          }
          break;
\end{verbatim}


Here you can see that it checks the left and right arguments to see if
they are scalar and acts optimally accordingly, using the {\tt
getScalar} function (rather than the {\tt eval} function) to return the
scalar result.  But notice that the case of both right and left being
scalar is missing.  What happens is that the {\tt eval} function is only
called by the next object up the tree if the result of that current
operation is NOT scalar.  If the result is a scalar, then {\tt eval} is
not called, but {\tt getScalar} is called.  For {\tt LELBinary} the
piece relevant to operator $+$ looks like

\begin{verbatim}
   template <class T>
   T LELBinary<T>::getScalar() const
   {
      switch(op_p) {
      case LELBinaryEnums::ADD :
         return pLeftExpr_p->getScalar() + pRightExpr_p->getScalar();
\end{verbatim}


So if we had asked for  {\tt 2.0 + min(c)}  then  both the arguments
would be scalars; the tree would be

\begin{verbatim}
      +
  2.0   min
         c
\end{verbatim}

and {\tt LELBinary::getScalar} would have been called to evaluate
the sum rather than {\tt LELBinary::eval}.   Now if this expression
was being used like

\begin{verbatim}
   a.copyData(2+min(c));
\end{verbatim}

then the {\tt Lattice} {\tt a} will have all of its pixels assigned the
same scalar value that resulted from the expression evaluation.
This final assignment decision is handled in the {\tt LatticeExprNode}
{\tt eval} functions.  



\section {Optimizations}

In the previous section, we considered an expression like 

\begin{verbatim}
   a.copyData(b+min(c));
\end{verbatim}

where the result of {\tt min(c)} is a scalar.  The {\tt Lattice} expressions
classes, normally evaluate their expressions chunk by chunk (tile by
tile).  However, it is clear that an expression like {\tt min(c)} should
only be evaluated once, and thereafter, for every chunk of the output
{\tt Lattice}, {\tt a}, that pre-evaluated scalar result used.

Let us look at one of the {\tt eval} function calls in {\tt LatticeExprNode}.
Recall that this is the function that the {\tt Lattice::copyData} is eventually
going to end up invoking and there is one for each data type 
depending upon the type of the output {\tt Lattice}.  Let us look at the
{\tt Float} version.

\begin{verbatim}
   void LatticeExprNode::eval (Array<Float>& result,
                               const PixelRegion& region) const
   {
      DebugAssert (dataType() == TpFloat, AipsError);
      if (!donePrepare_p) {
 
   // If first time, try to do optimization.
 
         LatticeExprNode* This = (LatticeExprNode*)this;
         LELInterface<Float>::replaceScalarExpr (This->pExprFloat_p);
         This->donePrepare_p = True;
      }
      if (isScalar()) {
         result = pExprFloat_p->getScalar();   
      } else {
         Array<Float> temp(result.shape());
         pExprFloat_p->eval(temp, region);   
         result = temp;
      }
   }
\end{verbatim}


The only optimization we do at present is to replace expressions
that result in a scalar by a scalar expression ({\tt LELUnaryConst}).

So, the first time this function is entered, the optimization is
attempted.  Thereafter, the expression is just evaluated.  Note that the
caste is necessary to convert the const {\tt LatticeExprNode} object to a
non-const one so we can change it (yuck) !

The implementation of the static function {\tt LELInterface::replaceScalarExpr} is

\begin{verbatim}
   template<class T>
   void LELInterface<T>::replaceScalarExpr (CountedPtr<LELInterface<T> >& expr)
   {
       expr->prepare();
       if (expr->isScalar()) {
           expr = new LELUnaryConst<T> (expr->getScalar());
       }
   }
\end{verbatim}

So it takes a {\tt CountedPtr<LELInterface>} and then does two things. 
First, the {\tt prepare} function is called.  Second, if the result of
the input expression is a scalar, it evaluates the value of the scalar
with the {\tt getScalar} function and replaces the expression by a {\tt
LELUnaryConst} object of that scalar value and appropriate type. 

Each of the {\tt LEL*} classes derived from {\tt LELInterface} has a
prepare function.  These either do nothing, or call replaceScalarExpr. 
Thus the process is recursive. 

Let us consider a couple of simple examples.  One that does no
optimzation and one that does.

Consider the expression 

\begin{verbatim}
   LatticeExprNode myExpr = a+b;
\end{verbatim}

where {\tt a} and {\tt b} are {\tt Float} {\tt Lattices}.  The tree is 

\begin{verbatim}
  +
a   b
\end{verbatim}



After construction of the tree, the {\tt LatticeExprNode} object {\tt myExpr} has
one active {\tt LELInterface} pointer, {\tt pExprFloat}$_{\tt p}$, which points at the
{\tt LELBinary} object constructed to handle the $+$ operation.  The
{\tt LELBinaryObject} has two internal {\tt LELInterface} pointers, one for each of
the left and right expressions (call them {\tt pLeft\_p} and {\tt pRight\_p}).  These
pointers each point at a {\tt LELLattice} object, one for each Lattice.  The
{\tt LELLattice} objects maintain pointers to the actual {\tt Lattice} objects. 
This is summarized in the following table. 


\begin{center}
\begin{tabular}{|l|l|l|l}
\hline
Object & Contains a & Points at a & Expressions \\
       & LELInterface$<$Float$>*$ & &    \\
\hline
myExpr  &   pExprFloat\_p  & LELBinary$<$Float$>$  & a+b \\
*pExprFloat\_p  &  pLeft\_p  &  LELLattice$<$Float$>$ &  a \\
                   &  pRight\_p  &  LELLattice$<$Float$>$ &  b \\
\hline
\end{tabular}
\end{center}



Here is the sequence of events.  The numbers indicate the layer
of the tree that we have penetrated to.  1 is the top of the tree.


1. In {\tt LatticeExprNode::eval}, {\tt replaceScalarExpr(myExpr.pExprFloat\_p}) is called.  
{\tt replaceScalarExpr} renames the pointer passed to it in the argument list expr.  
This points at the {\tt LELBinary} object 

2. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELBinary} object calls prepare  
with {\tt expr->prepare()} 

3. In {\tt LELBinary::prepare}, {\tt replaceScalarExpr(pLeft\_p)} is called.

4. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELLattice} object calls 
prepare with {\tt expr->prepare()} 

5. In {\tt LELLattice::prepare}; this does nothing and we 
return to {\tt LELInterface::replaceScalarExpr} 

4. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating the {\tt LELLattice} 
expression is seen to not be a scalar and we return  to {\tt LELBinary::prepare} 

3. In {\tt LELBinary::prepare},  {\tt replaceScalarExpr(pRight\_p)} is called. 

4. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELLattice} object calls prepare
with {\tt expr->prepare()}.  

5. In {\tt LELLattice::prepare}; this does nothing and we 
return to {\tt LELInterface::replaceScalarExpr} 

4. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating the LELLattice  
expression is seen to not be a scalar and we return to {\tt LELBinary::prepare} 

3. In {\tt LELBinary::prepare}, we return to {\tt LELInterface::replaceScalarExpr} 

2. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating the {\tt LELBinary} expression 
is seen to not be a scalar and we return to {\tt LatticeExprNode::eval} 

1.  In {\tt LatticeExprNode::eval} we note that we have done the optimization 
and now evaluate the expression {\tt a+b}.


The net result of all this was that nothing happened.  This was because
there were no scalar expressions to optimize.  


Now let's consider an expression where the optimization will occur. 
Consider the expression 

\begin{verbatim}
   LatticeExprNode myExpr = a+min(b);
\end{verbatim}

where {\tt a} and {\tt b} are {\tt Float} {\tt Lattices}.  The tree is 

\begin{verbatim}
  +
a   min
     b
\end{verbatim}

The min function returns a scalar - the minimum of the {\tt Lattice} {\tt b}
which should be added to the pixels of {\tt Lattice} {\tt a}.  We should be able
to optimize it out of the iteration loop and replace the tree by

\begin{verbatim}
  +
a   constant
\end{verbatim}


After construction of the tree, the {\tt LatticeExprNode} object {\tt
myExpr} has one active {\tt LELInterface} pointer, {\tt pExprFloat\_p},
which points at the {\tt LELBinary} object constructed to handle the $+$
operation.  The {\tt LELBinaryObject} has two internal {\tt
LELInterface} pointers, one for each of the left and right expressions
(call them {\tt pLeft\_p} and {\tt pRight\_p}).  {\tt pLeft\_p}
points at a {\tt LELLattice} object, for {\tt Lattice} {\tt a}.  {\tt
pRight\_p} points at a {\tt LELFunction1D} object to handle the {\tt
min} function.  This {\tt LELFunction1D} object has a {\tt LELInterface}
pointer called {\tt pExpr\_p} which points at a {\tt LELLattice} object, for
{\tt Lattice} {\tt b}.  This is summarized in the following table. 


\begin{center}
\begin{tabular}{|l|l|l|l}
\hline
Object & Contains a & Points at a & Expressions \\
       & LELInterface$<$Float$>*$ & &    \\
\hline
myExpr  &         pExprFloat\_p   &  LELBinary$<$Float$>$ &     a+min(b) \\
*pExprFloat\_p  &  pLeft\_p   &  LELLattice$<$Float$>$ &   a \\
               &  pRight\_p  &  LELFunction1D$<$Float$>$ &   min(b) \\
*pRight\_p      &  pExpr\_p   &  LELLattice$<$Float$>$  &  b \\
\hline
\end{tabular}
\end{center}



Here is the sequence of events.  The numbers indicate the layer
of the tree that we have penetrated to.  1 is the top of the tree.

1. In {\tt LatticeExprNode::eval}, {\tt replaceScalarExpr(myExpr.pExprFloat\_p}) is called.  
{\tt replaceScalarExpr} calls the pointer passed to it in the argument list "expr"  
This  points at the {\tt LELBinary} object
   
2. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELBinary} object calls prepare 
with {\tt expr->prepare()} 

3. In {\tt LELBinary::prepare},  {\tt replaceScalarExpr(pLeft\_p}) is called.   
{\tt pLeft\_p} points at a {\tt LELLattice} object

4. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELLattice} object calls 
prepare with {\tt expr->prepare()}.

5. In {\tt LELLattice::prepare}; this does nothing and we 
return to {\tt LELInterface::replaceScalarExpr}

4. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating the 
{\tt LELLattice} expression is seen to not be a scalar and we 
return  to {\tt LELBinary::prepare}

3. In {\tt LELBinary::prepare}, {\tt replaceScalarExpr(pRight\_p}) is called; 
{\tt pRight\_p} points to a {\tt LELFunction1D} object this time.

4. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELFunction1D} object calls 
prepare with {\tt expr->prepare()}.

5. In {\tt LELFunction1D::prepare}, {\tt replaceScalarExpr(pExpr\_p}) is called 

6. In {\tt LELInterface::replaceScalarExpr}, the {\tt LELLattice} object calls 
prepare with {\tt expr->prepare()}.

7. In {\tt LELLattice::prepare}; this does nothing and we return 
to {\tt LELInterface::replaceScalarExpr}

6. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating 
the  {\tt LELLattice} expression is seen to not be a scalar and 
we return to  {\tt LELFunction1D::prepare}

5. In {\tt LELFunction1D::prepare}, we return to {\tt LELInterface::replaceScalarExpr} 

4. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating 
the {\tt LELFunction1D} expression IS seen to be a scalar.  We evaluate 
that scalar value (another recursive chain) with the {\tt getScalar} function via 
the call {\tt expr->getScalar()}. We replace  the object pointed at by {\tt expr} 
(in this case, {\tt expr} is pointing at a {\tt LELFunction1D} object) 
by a {\tt LELUnaryConst} object constructed with the result of the 
{\tt getScalar} call

We return to {\tt LELBinary::prepare}

3. From {\tt LELBinary::prepare}, we return to {\tt LELInterface::replaceScalarExpr}.

2. In {\tt LELInterface::replaceScalarExpr}, the result of evaluating 
the {\tt LELBinary} expression is seen to not be a scalar and 
we return to {\tt LatticeExprNode::eval}

1. In {\tt LatticeExprNode::eval} we note that we have done the optimization 
and now evaluate the expression {\tt a+constant}



Note that the call to getScalar by the {\tt LELFunction1D} object invokes a recursive
chain as well, although it doesn't go far in this case.  Let's look inside the
{\tt LELFunction1D::getScalar} function and see what happens there.  The relevant piece
is implemented according to

\begin{verbatim}
   template <class T>
   T LELFunction1D<T>::getScalar() const
   {
      switch(function_p) {
      case LELFunctionEnums::MIN1D :
      {
         if (pExpr_p->isScalar()) {
            return pExpr_p->getScalar();
         }   
         Bool firstTime = True;
         T minVal = T();
         LatticeExpr<T> latExpr(pExpr_p, 0);
         RO_LatticeIterator<T> iter(latExpr, latExpr.niceCursorShape());
         while (! iter.atEnd()) {
            T minv = min(iter.cursor());
            if (firstTime  ||  minv < minVal) {
               firstTime = False;
               minVal = minv;
            }
            iter++;
         }
         return minVal;
      }
\end{verbatim}


The {\tt LELInterface} pointer {\tt pExpr\_p}, is pointing at a {\tt
LELLattice} object, which was constructed from the actual {\tt Lattice},
{\tt b}.  First it looks to see whether the expression in hand, the {\tt
LELLattice} expression, is a scalar or not.  If it is, it finds the
value and returns.  For example, if we had asked for {\tt min(2.0)} this
would happen.  If it isn't, then we continue on.  Now again, {\tt
pExpr\_p} is pointing at a {\tt LELLattice} object (derived from {\tt
LELInterface}).  But that is not a {\tt Lattice}; we need to get at the
{\tt Lattice} from which it was constructed.  Since we are inside class
{\tt LELFunction1D}, we can't get at the pointer inside the {\tt
LELLattice} class which does point at the {\tt Lattice}.  Thus, instead,
we construct a {\tt LatticeExpr<T>} object (which does inherit from
{\tt Lattice}) from the {\tt LELLattice}. 

This happens with the constructor

\begin{verbatim}
   LatticeExprNode(LELInterface<Float>* expr);
\end{verbatim}

which makes a {\tt LatticeExprNode}.  From there it is converted to
a {\tt LatticeExpr} via the casting operators described in section 2.1
Then it is a simple matter to create a {\tt Lattice} iterator, iterate through
the {\tt Lattice} (via the {\tt LatticeExpr}) and work out the minimum value.


\section {Relational and Logical Expressions}

\subsection {Relational Expressions}

So far in the discussion, it has been assumed that the result of all
expressions was either a numeric array or scalar.  However, we also want
to be able to handle operations which result in {\tt Boolean}s.  For
example, consider {\tt Lattices}

\begin{verbatim}
   Lattice<Float> a;
   Lattice<Float> b;
   Lattice<Bool> c;
\end{verbatim}

and the expression

\begin{verbatim}
   c.copyData(a>b);
\end{verbatim}

so the {\tt Bool} {\tt Lattice} {\tt c} is {\tt True} or {\tt False}
depending upon whether the data values of {\tt a} were greater than
those of {\tt b} or not. 

What has to be handled here is that the output of the $>$ operation
is {\tt Boolean}, whereas the type of the data which went into the operation
was {\tt Float}.

This relational operator, and like ones ($<$, $>=$, $<=$, $==$, !$=$)
are handled in the class {\tt LELBinaryCmp}.  It is templated on class
{\tt T} but inherits from {\tt LELInterface<Bool>} rather than {\tt
LELInterface<T>}. 

The {\tt LELInterface} class {\tt eval} function is declared as

\begin{verbatim}
   // Evaluate the expression and fill the result array
      virtual void eval (Array<T>& result,
                         const PixelRegion& region) const = 0;
\end{verbatim}
 

This indicates that the array, {\tt result}, which results from
evaluating the expression is of type {\tt T}.  Since {\tt LELBinaryCmp}
inherits from {\tt LELInterface<Bool>}, the type of its evaluation
array, result, is Bool.  This is just what we want.  The result of {\tt b>c}
is a {\tt Bool} array. 

The {\tt LELBinaryCmp} class itself is still templated in class {\tt T}
because that is the type of the {\tt Lattices} that go into it. 


\subsection {Logical Expressions}

Take as an example,

\begin{verbatim}
   Lattice<Bool> a;
   Lattice<Bool> b;
   Lattice<Bool> c;
   c.copyData(a&&b);
\end{verbatim}

so the {\tt Bool} {\tt Lattice} {\tt c} is {\tt True} if {\tt Lattice}
{\tt a} and {\tt b} are {\tt True}.  This kind of operator can only be
defined for {\tt Boolean} {\tt Lattices}.  Therefore the class {\tt
LELBinaryBool} is not templated and inherits from {\tt
LELInterface<Bool>}.  If the data types of the {\tt Lattices} are not
{\tt Bool} it will throw an exception. 

Similarly, the class {\tt LELUnaryBool} exists to handle unary logical
operations such as  

\begin{verbatim}
   c.copyData(!a)
\end{verbatim}


\section {Other Specializations}


There are a few other specialized classes because not all possible data
types can be handled by some functions.  For example, {\tt
LELFunctionReal1D} is a specialized version of {\tt LELFunction1D}.  The
former exists to handle functions such as {\tt asin}, {\tt acos} etc
which only function with real data. 

Similarly, the classes {\tt
LELFunction\{Float,Double,Complex,DComplex\}} exist to handle functions
with an arbitrary number of arguments for each data type.  Probably some
of these could be combined into a templated class in the same way as the
1-argument {\tt LELFunction*1D} classes, but there is enough difference
between them to make this worthwhile. 

Deserving of special mention for their cunning implementation are the
functions, {\tt nelements}, {\tt ntrue}, and {\tt nfalse}.  These are
implemented in {\tt LELFunctionDouble}, which is not templated and it
inherits from {\tt LELInterface<Double>}. 

\subsection {Function {\tt nelements}}

Consider the expression

\begin{verbatim}
   Lattice<Bool> b;
   Lattice<Double> a;
   a.copyData(nelements(b));
\end{verbatim}


Function {\tt nelements} operates on a {\tt Lattice} of any data type,
and returns the number of elements in the {\tt Lattice} in a {\tt
Double}.  {\tt LELFunctionDouble} is not templated, and yet this
function handles {\tt Lattices} of any type.  It is implemented directly
in {\tt LatticeExprNode}

\begin{verbatim}
   LatticeExprNode nelements(const LatticeExprNode& expr)
   {
      Block<LatticeExprNode> arg(1, expr);
      return new LELFunctionDouble (LELFunctionEnums::NELEM, arg);
   }
\end{verbatim}


The new statement creates a pointer to a {\tt LELFunctionDouble} object,
which inherits from {\tt LELInterface<Double>}.  This is then
automatically converted to a {\tt LatticeExprNode} by the constructor

\begin{verbatim}
   LatticeExprNode(LELInterface<Double>* expr);
\end{verbatim}

Now, {\tt LELFunctionDouble} knows that the result of function {\tt
nelements} is a scalar, so it is only implemented in {\tt getScalar}. 
The implementation in {\tt LELFunctionDouble::getScalar} is

\begin{verbatim}
   case LELFunctionEnums::NELEM :
       if (arg_p[0].isScalar()) {
          return 1;
       }
       return arg_p[0].shape().product();
\end{verbatim}

{\tt arg\_p[0]} is the first element in a {\tt Block<LatticeExprNode>}. 
In our example, it is a {\tt LatticeExprNode} housing the {\tt
LELLattice} object that is needed to access the Lattice<Bool> ({\tt b}). 
Now recall that {\tt LELLattice} is fully templated, so it can of course
handle any type of Lattice.  But {\tt LELFunctionDouble} doesn't know
anything at all about the type of this Lattice in the path that is
followed for this function; all type checking is bypassed.  The
statement {\tt arg\_p[0].shape().product()} invokes the appropriate
{\tt LatticeExprNode} function to return the shape attribute.


\subsection {Functions {\tt ntrue} and {\tt nfalse}}

These functions only work on Bool {\tt Lattices} and count
up the number of {\tt True} or {\tt False} values.  Like {\tt nelements}
they are implemented directly from {\tt LatticeExprNode}.
E.g.

\begin{verbatim}
   LatticeExprNode ntrue (const LatticeExprNode& expr)   
   {
      AlwaysAssert (expr.dataType() == TpBool, AipsError);
      Block<LatticeExprNode> arg(1, expr);
      return new LELFunctionDouble(LELFunctionEnums::NTRUE, arg);
   }
\end{verbatim}


Immediately though a test is made for the type of the expression that is
having the function applied to it.  If it's not a {\tt Bool}, an
exception is thrown.  Otherwise we proceed into {\tt LELFunctionDouble}
again.  Since the result is a scalar they are only implemented in {\tt
LELFunctionDouble::getScalar} For example, for {\tt ntrue}

\begin{verbatim}
   switch (function_p) {
   case LELFunctionEnums::NTRUE :
   {
      uInt ntrue = 0;
      Bool deleteIt;
      LatticeExpr<Bool> latExpr(arg_p[0], 0);
      RO_LatticeIterator<Bool> iter(latExpr, latExpr.niceCursorShape());
      while (! iter.atEnd()) {
         const Array<Bool>& array = iter.cursor();
         const Bool* data = array.getStorage (deleteIt);
         uInt n = array.nelements();
         for (uInt i=0; i<n; i++) {
            if (data[i]) {
               ntrue++;
            }
         }
         array.freeStorage (data, deleteIt);
         iter++;
      }
      return ntrue; 
   }
\end{verbatim}
 
A {\tt LatticeExpr<Bool>} (which is a {\tt Lattice}) is explicitly
created from the {\tt LatticeExprNode} via the constructor.  This is
then iterated through to get implement the function. 


\section {Static LatticeExprNode functions}

The following table lists helper functions in {\tt LatticeExprNode}
and their uses for creating appropriate nodes in the tree.


\begin{center}
\begin{tabular}{|l|l}
\hline
LatticeExprNode &  Reason \\
  function      & \\
\hline
newNumUnary  &     Create a new node for a numerical unary operation. \\
&                  The result has the same data type as the input \\
newNumBinary &     Create a new node for a numerical binary operator.  \\
             &    The result has the same data type as the combined input type. \\
newBinaryCmp &    Create a new node for a comparison binary operator. \\
             &     The result has the same data type as the combined input type. \\
newNumFunc1D  &    Create a new node for a numerical function with 1 argument. \\
              &   The result has the same data type as the input. \\
newRealFunc1D  &   Create a new node for a real numerical function with 1 \\
               &  argument. The result has the same data type as the input. \\
newComplexFunc1D &  Create a new node for a complex numerical function with 1 \\
                 &  argument. The result has the same data type as the input. \\
newNumReal1D     & Create a new node for a real numerical function with 1 \\
                 &  argument. The resultant type is non-complex \\
newNumFunc2D     & Create a new node for a numerical function with 2 arguments. \\
                 & The result has the same data type as the combined input type. \\
\hline
\end{tabular}
\end{center}

\section {Memory Management}

Although there are many {\tt new} statements in these classes, there are
no matching {\tt delete} statements.  This is because all the pointers
are {\tt CountedPtr} objects and that class handles the cleanup of
released memory. 




\section {Functionality}

In this section we list the full functionality available in the {\tt
LEL} classes.    

The next small table lists the data type codes used subsequently.

\begin{center}
\begin{tabular}{|l|l}
\hline
Type & Code \\
\hline
Float      & 1 \\
Double     & 2 \\
Complex    & 3 \\
DComplex   & 4 \\
Bool       & 5 \\
\hline
\end{tabular}
\end{center}


First we give a descriptive table of the available classes and the generic input
Lattice expression types and output types that they handle.


\begin{center}
\begin{tabular}{|l|l|l|l}
\hline
 Class  & Description & Type that Operates on & Return Type \\
\hline
LELLattice   & Reads Lattice pixels & 1,2,3,4,5 & 1,2,3,4,5 \\
LELUnary     & Handles numerical unary operators & 1,2,3,4 & 1,2,3,4 \\
LELUnaryConst & Handles scalar constants & 1,2,3,4,5 & 1,2,3,4,5 \\
LELUnaryBool  &  Handles logical unary operators & 5 & 5 \\
LELBinary   &  Handles numerical binary operators & 1,2,3,4 & 1,2,3,4 \\
LELBinaryCmp  &  Handles relational binary numerical operators & 1,2,3,4 & 5 \\
LELBinaryBool &  Handles logical binary operators & 5 & 5 \\
LELFunction1D &  Handles numerical 1-argument functions  & 1,2,3,4 & 1,2,3,4 \\
LELFunctionND &  Handles numerical N-argument functions  & 1,2,3,4 & 1,2,3,4 \\
LELFunctionReal1D &  Handles real numerical 1-argument functions & 1,2 & 1,2 \\
LELFunctionFloat  &   Handles numerical N-argument functions returning Float & 1,3 & 1 \\
LELFunctionDouble &   Handles numerical N-argument functions returning Double & 2,4 & 2 \\
LELFunctionComplex &   Handles complex numerical N-argument functions & 3 & 3 \\
LELFunctionDComplex &  Handles double complex numerical N-argument functions & 4 & 4 \\
LELFunctionBool     &  Handles logical N-argument functions & 5 & 5 \\
\hline
\end{tabular}
\end{center}

Note that some classes are essentially non-templated specializations of
others.  For example, {\tt LELFunctionReal1D} handles functions that
couldn't be in {\tt LELFunction1D} because there was no complex version
of that function (e.g.  {\tt asin}) so templating would fail. 

  
In the usage column of the last table, the examples use
the following objects:

\begin{verbatim}
   Lattice<Float> a;
   Lattice<Float> b;
   Lattice<Double> aDouble;
   Lattice<Double> bDouble;
   Lattice<Complex> aComplex;
   Lattice<Complex> bComplex;
   Lattice<DComplex> aDComplex;
   Lattice<DComplex> bDComplex;
   Lattice<Bool> aBool;
   Lattice<Bool> bBool;
   Double const;
   LatticeExprNode expr; 
\end{verbatim}


\newpage
\begin{center}
\begin{tabular}{|l|l|l|l|l|l}
\hline
 Class  & Operation  & Input Data Type  & Result dim. & Arguments  & Usage example \\
\hline
LELLattice   &       getSlice   &   1,2,3,4,5  &  Array           &   1   &    expr = a \\
LELUnary     &        -         &   1,2,3,4    &  Scalar,Array    &   1   &   expr = $-a$ \\  
             &         +        &   1,2,3,4    &   Scalar,Array   &   1   &   expr = +a (does nothing) \\
LELUnaryConst &      constant   &   1,2,3,4,5  &   Scalar         &   1   &   expr = const \\ 
LELUnaryBool  &        !        &   5          &   Scalar,Array   &   1   &   expr = !aBool \\ 
LELBinary   &          +        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a+b \\   
             &         -        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a$-$b \\ 
              &        *        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a*b \\
               &       /        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a/b \\
LELBinaryCmp  &        ==       &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a==b \\  
               &       !=       &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a!=b \\  
                &      $>$        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a$>$b \\ 
              &        $<$        &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a$<$b \\
               &       $>=$       &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a$>=$b \\
                &      $>=$       &   1,2,3,4    &   Scalar,Array   &   2   &   expr = a$<=$b \\
LELBinaryBool &        ==       &   5          &   Scalar,Array   &   2   &   expr = aBool==bBool \\
               &       !=       &   5          &   Scalar,Array   &   2   &   expr = aBool!=bBool \\
                &      \&\&     &   5          &   Scalar,Array   &   2   &   expr = Bool\&\&bBool \\
                 &     $||$       &   5          &   Scalar,Array   &   2   &   expr = Bool$||$bBool \\
LELFunction1D &        sin      &   1,2,3,4    &   Scalar,Array   &   1   &   expr = sin(a) \\  
               &       sinh     &   1,2,3,4    &   Scalar,Array   &   1   &   expr = sinh(a) \\ 
                &      cos      &   1,2,3,4    &   Scalar,Array   &   1   &   expr = cos(a) \\  
                 &     cosh     &   1,2,3,4    &   Scalar,Array   &   1   &   expr = cosh(a) \\   
                  &    exp      &   1,2,3,4    &   Scalar,Array   &   1   &   expr = exp(a) \\   
              &        log      &   1,2,3,4    &   Scalar,Array   &   1   &   expr = log(a) \\
               &       log10    &   1,2,3,4    &   Scalar,Array   &   1   &   expr = log10(a) \\
                &      sqrt     &   1,2,3,4    &   Scalar,Array   &   1   &   expr = sqrt(a) \\
                 &     min      &   1,2,3,4    &   Scalar         &   1   &   expr = min(a) \\
              &        max      &   1,2,3,4    &   Scalar         &   1   &   expr = max(a) \\
               &       mean     &   1,2,3,4    &   Scalar         &   1   &   expr = meann(a) \\
                &      sum      &   1,2,3,4    &   Scalar         &   1   &   expr = sum(a) \\
LELFunctionND &        iif      &   1,2,3,4    &   Scalar,Array   &   1   &   expr = iif(aBool,a,b) \\  
LELFunctionReal1D &    asin     &   1,2        &   Scalar,Array   &   1   &   expr = asin(a) \\
                  &    acos     &   1,2        &   Scalar,Array   &   1   &   expr = acos(a) \\
                  &    tan      &   1,2        &   Scalar,Array   &   1   &   expr = tan(a) \\
                  &    atan     &   1,2        &   Scalar,Array   &   1   &   expr = atan(a) \\
                  &    tanh     &   1,2        &   Scalar,Array   &   1   &   expr = tanh(a) \\
                  &    ceil     &   1,2        &   Scalar,Array   &   1   &   expr = ceil(a) \\
                  &    floor    &   1,2        &   Scalar,Array   &   1   &   expr = floor(a) \\
LELFunctionFloat  &    min      &   1          &   Scalar,Array   &   2   &   expr = min(a,b) \\
                  &    max      &   1          &   Scalar,Array   &   2   &   expr = max(a,b) \\
                  &    pow      &   1          &   Scalar,Array   &   2   &   expr = pow(a,b) \\
                  &    atan2    &   1          &   Scalar,Array   &   2   &   expr = atan2(a,b) \\
                  &    fmod     &   1          &   Scalar,Array   &   2   &   expr = fmod(a,b) \\
                  &    abs      &   1,3        &   Scalar,Array   &   1   &   expr = abs(a), abs(aComplex) \\
                  &    arg      &   3          &   Scalar,Array   &   1   &   expr = arg(aComplex) \\
                  &    real     &   1,3        &   Scalar,Array   &   1   &   expr = real(aComplex) \\
                  &    imag     &   1,3        &   Scalar,Array   &   1   &   expr = imag(aComplex) \\
\hline
\end{tabular}
\end{center}
 

\newpage
\begin{center}
\begin{tabular}{|l|l|l|l|l|l}
\hline
 Class  & Operation  & Input Data Type  & Result dim. & Arguments  & Usage example \\
\hline
LELFunctionDouble &    min      &   2          &   Scalar,Array   &   2   &   expr = min(aDouble,bDouble) \\
                  &    max      &   2          &   Scalar,Array   &   2   &   expr = max(aDouble,bDouble) \\
                  &    pow      &   2          &   Scalar,Array   &   2   &   expr = pow(aDouble,bDouble) \\
                  &    atan2    &   2          &   Scalar,Array   &   2   &   expr = atan2(aDouble,bDouble) \\
                  &    fmod     &   2          &   Scalar,Array   &   2   &   expr = fmod(aDouble,bDouble) \\
                  &    abs      &   2,4        &   Scalar,Array   &   1   &   expr = abs(aDouble), abs(aDComplex) \\
                  &    arg      &   4          &   Scalar,Array   &   1   &   expr = arg(aDComplex) \\
                  &    real     &   2,4        &   Scalar,Array   &   1   &   expr = real(aDComplex) \\
                  &    imag     &   2,4        &   Scalar,Array   &   1   &   expr = imag(aDComplex) \\
LELFunctionDouble &    ntrue    &   5          &   Scalar         &   1   &   expr = ntrue(aBool) \\
                  &    nfalse   &   5          &   Scalar         &   1   &   expr = nfalse(aBool) \\
LELFunctionDouble &    nelements&   Any        &   Scalar         &   1   &   expr = nelements(a) \\
LELFunctionComplex &   pow      &   3          &   Scalar,Array   &   2   &   expr = pow(aComplex,bComplex) \\
                   &   conj     &   3          &   Scalar,Array   &   1   &   expr = conj(aComplex) \\
LELFunctionDComplex &   pow     &   4          &   Scalar,Array   &   2   &   expr = pow(aDComplex,bDComplex) \\
                    &  conj     &   4          &   Scalar,Array   &   1   &   expr = conj(aComplex) \\
LELFunctionBool     &  all      &   5          &   Scalar         &   1   &   expr = all(aBool) \\
                    &  any      &   5          &   Scalar         &   1   &   expr = any(aBool) \\
LatticeExprNode   &    amp      &   1,2,3,4    &   Scalar,Array   &   2   &   expr = amp(a,b) \\
LatticeExprNode   &    pa       &   1,2        &   Scalar,Array   &   2   &   expr = pa(a,b) \\

\hline
\end{tabular}
\end{center}





